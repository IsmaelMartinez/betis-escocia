# AI Assistant Research - PeÃ±a BÃ©tica Escocesa

> **Date**: December 2025  
> **Status**: Research  
> **Goal**: Implement a cheap AI assistant restricted to Betis/Escocia/PeÃ±a BÃ©tica topics

## Executive Summary

This document analyzes options for implementing an AI chatbot assistant that:
1. Uses a **free or very cheap** LLM API
2. Is **topic-restricted** to Real Betis, Scotland football, and PeÃ±a BÃ©tica matters
3. Integrates seamlessly with the existing Next.js 15 architecture

**Recommended Solution**: Google Gemini API (free tier) with system prompt-based topic restriction.

---

## 1. LLM Provider Comparison

### ğŸ† Google Gemini (Recommended)

| Aspect | Details |
|--------|---------|
| **Free Tier** | âœ… **15 requests/minute, 1,500 requests/day** (Gemini 1.5 Flash) |
| **Pricing** | \$0.075 per 1M input tokens, \$0.30 per 1M output tokens (paid tier) |
| **Models** | Gemini 2.0 Flash, Gemini 1.5 Flash, Gemini 1.5 Pro |
| **API** | REST API with official Node.js SDK (\`@google/generative-ai\`) |
| **Context Window** | 1M tokens (Gemini 1.5 Flash) |
| **Speed** | Very fast responses (~1-2 seconds) |
| **Rate Limits** | Generous for a community website |

**Why Gemini is Best for This Project:**
- **Completely free** for low-to-moderate traffic (1,500 requests/day = ~50 users Ã— 30 messages)
- Simple SDK integration with Next.js
- Excellent for conversational AI with topic restriction
- No credit card required for free tier

### Alternative Options

#### Groq (Free Tier)

| Aspect | Details |
|--------|---------|
| **Free Tier** | âœ… 14,400 requests/day (varies by model) |
| **Models** | Llama 3.1, Mistral, Mixtral |
| **Speed** | **Extremely fast** (fastest inference available) |
| **Context Window** | 8K-128K depending on model |
| **SDK** | Node.js SDK available |

**Pros**: Fastest responses, generous free tier  
**Cons**: Hosted models only (no Gemini/GPT), less refined conversation quality

#### OpenAI (GPT-3.5/GPT-4)

| Aspect | Details |
|--------|---------|
| **Free Tier** | âŒ No free tier (pay-per-use only) |
| **Pricing** | GPT-3.5: \$0.50/1M tokens, GPT-4: \$30/1M tokens |
| **Quality** | Highest conversation quality |

**Not recommended** - No free tier, higher cost.

#### Anthropic Claude

| Aspect | Details |
|--------|---------|
| **Free Tier** | âŒ No free API tier |
| **Pricing** | Claude 3 Haiku: \$0.25/1M input, \$1.25/1M output |
| **Quality** | Excellent conversation quality |

**Not recommended** - No free API tier.

#### Cloudflare Workers AI

| Aspect | Details |
|--------|---------|
| **Free Tier** | âœ… 10,000 neurons/day (roughly 100-500 requests) |
| **Models** | Llama 3, Mistral, Phi-2 |
| **Integration** | Works great with Vercel/Cloudflare |

**Backup option** - Good if already using Cloudflare, limited free tier.

#### Ollama (Self-hosted)

| Aspect | Details |
|--------|---------|
| **Cost** | Free (requires server) |
| **Models** | Any open-source model (Llama, Mistral, etc.) |
| **Hosting** | Requires VPS (\$5-20/month) |

**Not recommended** - Requires infrastructure management.

---

## 2. Topic Restriction Strategy

### Approach: System Prompt + Input Validation

The most effective way to restrict the AI to specific topics is a **multi-layered approach**:

#### Layer 1: System Prompt (Primary)

\`\`\`typescript
const SYSTEM_PROMPT = \`Eres el asistente virtual de la PeÃ±a BÃ©tica Escocesa, un club de aficionados del Real Betis BalompiÃ© ubicado en Edimburgo, Escocia.

**REGLAS ESTRICTAS:**
1. SOLO puedes responder preguntas sobre:
   - Real Betis BalompiÃ© (historia, jugadores, partidos, estadÃ­sticas)
   - FÃºtbol escocÃ©s y la SelecciÃ³n de Escocia
   - La PeÃ±a BÃ©tica Escocesa (eventos, membresÃ­a, ubicaciÃ³n)
   - El pub Polwarth Tavern donde vemos los partidos
   - La ciudad de Edimburgo y puntos de interÃ©s para bÃ©ticos visitantes

2. Si alguien pregunta sobre otros temas, responde amablemente:
   "Lo siento, soy el asistente de la PeÃ±a BÃ©tica Escocesa y solo puedo ayudarte con temas relacionados con el Real Betis, fÃºtbol escocÃ©s, o nuestra peÃ±a. Â¿Puedo ayudarte con algo sobre estos temas?"

3. Siempre responde en el mismo idioma en que te preguntan (espaÃ±ol o inglÃ©s).

4. SÃ© amigable, entusiasta sobre el Betis, y usa expresiones bÃ©ticas como "Â¡Viva el Betis!" cuando sea apropiado.

5. InformaciÃ³n clave de la peÃ±a:
   - UbicaciÃ³n: Polwarth Tavern, Edimburgo
   - Eventos: Vemos todos los partidos del Betis juntos
   - Contacto: A travÃ©s de la pÃ¡gina web
   - Trivia: Tenemos un juego de trivia diario sobre el Betis\`;
\`\`\`

#### Layer 2: Input Keyword Filtering (Secondary)

Pre-check user messages for off-topic signals:

\`\`\`typescript
const ALLOWED_TOPICS = [
  // Spanish
  'betis', 'betico', 'bÃ©ticos', 'verdiblanco', 'heliÃ³polis', 'benito villamarÃ­n',
  'sevilla', 'la liga', 'liga espaÃ±ola', 'fÃºtbol', 'futbol',
  'escocia', 'edimburgo', 'scotland', 'edinburgh', 'scottish',
  'peÃ±a', 'pena', 'polwarth', 'tavern', 'pub',
  'partido', 'match', 'gol', 'jugador', 'player', 'entrenador', 'coach',
  'trivia', 'porra', 'rsvp', 'evento', 'event',
  // Common football terms
  'copa', 'champions', 'europa league', 'temporada', 'season',
  'fichaje', 'transfer', 'estadio', 'stadium',
  // Players/coaches (current and historical)
  'joaquÃ­n', 'fekir', 'pellegrini', 'isco', 'william carvalho',
  'lo celso', 'nabil', 'isco', 'juanmi', 'borja iglesias'
];

function isLikelyOnTopic(message: string): boolean {
  const normalized = message.toLowerCase();
  // Allow greetings and basic questions
  if (normalized.length < 20) return true;
  // Check for topic keywords
  return ALLOWED_TOPICS.some(topic => normalized.includes(topic));
}
\`\`\`

#### Layer 3: Response Validation (Tertiary)

Check AI responses to ensure they stay on topic:

\`\`\`typescript
const OFF_TOPIC_PHRASES = [
  'as an AI language model',
  'I cannot provide medical',
  'I cannot help with',
  'that is outside my scope'
];

function validateResponse(response: string): boolean {
  // If AI self-identifies as refusing, it's working correctly
  return !OFF_TOPIC_PHRASES.some(phrase => 
    response.toLowerCase().includes(phrase.toLowerCase())
  );
}
\`\`\`

---

## 3. Recommended Architecture

### Component Diagram

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              ChatWidget Component                   â”‚    â”‚
â”‚  â”‚  - Floating button in bottom-right                 â”‚    â”‚
â”‚  â”‚  - Expandable chat window                          â”‚    â”‚
â”‚  â”‚  - Message history (session storage)              â”‚    â”‚
â”‚  â”‚  - Typing indicators                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Route (/api/chat)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  1. Rate limiting (per IP/session)                 â”‚    â”‚
â”‚  â”‚  2. Input validation (Zod schema)                  â”‚    â”‚
â”‚  â”‚  3. Topic pre-filtering                            â”‚    â”‚
â”‚  â”‚  4. Gemini API call                                â”‚    â”‚
â”‚  â”‚  5. Response validation                            â”‚    â”‚
â”‚  â”‚  6. Error handling                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Google Gemini API (Free Tier)                  â”‚
â”‚  - Model: gemini-1.5-flash                                  â”‚
â”‚  - System prompt with topic restrictions                    â”‚
â”‚  - Streaming responses for better UX                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### File Structure

\`\`\`
src/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ chat/
â”‚           â””â”€â”€ route.ts          # Chat API endpoint
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatWidget.tsx            # Main chat widget
â”‚   â”œâ”€â”€ ChatMessage.tsx           # Individual message component
â”‚   â””â”€â”€ ChatInput.tsx             # Message input component
â””â”€â”€ lib/
    â””â”€â”€ chat/
        â”œâ”€â”€ geminiClient.ts       # Gemini SDK wrapper
        â”œâ”€â”€ topicFilter.ts        # Topic restriction logic
        â”œâ”€â”€ systemPrompt.ts       # System prompt configuration
        â””â”€â”€ types.ts              # TypeScript types
\`\`\`

---

## 4. Implementation Guide

### Step 1: Install Dependencies

\`\`\`bash
npm install @google/generative-ai
\`\`\`

### Step 2: Environment Variables

\`\`\`env
# .env.local
GOOGLE_GEMINI_API_KEY=your_api_key_here
\`\`\`

### Step 3: Gemini Client Setup

\`\`\`typescript
// src/lib/chat/geminiClient.ts
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY!);

export const geminiModel = genAI.getGenerativeModel({
  model: 'gemini-1.5-flash',
  systemInstruction: SYSTEM_PROMPT,
  generationConfig: {
    temperature: 0.7,
    topP: 0.8,
    topK: 40,
    maxOutputTokens: 500, // Keep responses concise
  },
});

export async function getChatResponse(
  message: string,
  history: Array<{ role: 'user' | 'model'; parts: string }>
): Promise<string> {
  const chat = geminiModel.startChat({
    history: history.map(h => ({
      role: h.role,
      parts: [{ text: h.parts }],
    })),
  });

  const result = await chat.sendMessage(message);
  return result.response.text();
}
\`\`\`

### Step 4: API Route

\`\`\`typescript
// src/app/api/chat/route.ts
import { createApiHandler } from '@/lib/apiUtils';
import { z } from 'zod';
import { getChatResponse } from '@/lib/chat/geminiClient';
import { isLikelyOnTopic } from '@/lib/chat/topicFilter';

const chatSchema = z.object({
  message: z.string().min(1).max(500),
  history: z.array(z.object({
    role: z.enum(['user', 'model']),
    parts: z.string(),
  })).max(20).optional().default([]),
});

export const POST = createApiHandler({
  auth: 'none', // Allow anonymous users
  schema: chatSchema,
  handler: async ({ message, history }) => {
    // Pre-filter obvious off-topic messages
    if (!isLikelyOnTopic(message)) {
      return {
        response: 'Lo siento, soy el asistente de la PeÃ±a BÃ©tica Escocesa. ' +
                  'Â¿Puedo ayudarte con algo sobre el Real Betis, fÃºtbol escocÃ©s, ' +
                  'o nuestra peÃ±a?',
        filtered: true,
      };
    }

    try {
      const response = await getChatResponse(message, history);
      return { response, filtered: false };
    } catch (error) {
      console.error('Gemini API error:', error);
      throw new Error('Error al procesar tu mensaje. IntÃ©ntalo de nuevo.');
    }
  },
});
\`\`\`

### Step 5: Chat Widget Component

\`\`\`typescript
// src/components/ChatWidget.tsx
'use client';

import { useState, useRef, useEffect } from 'react';
import { MessageCircle, X, Send, Loader2 } from 'lucide-react';

interface Message {
  role: 'user' | 'model';
  content: string;
  timestamp: Date;
}

export function ChatWidget() {
  const [isOpen, setIsOpen] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const sendMessage = async () => {
    if (!input.trim() || isLoading) return;

    const userMessage: Message = {
      role: 'user',
      content: input.trim(),
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: userMessage.content,
          history: messages.map(m => ({
            role: m.role,
            parts: m.content,
          })),
        }),
      });

      const data = await response.json();

      if (data.success) {
        setMessages(prev => [...prev, {
          role: 'model',
          content: data.data.response,
          timestamp: new Date(),
        }]);
      }
    } catch (error) {
      setMessages(prev => [...prev, {
        role: 'model',
        content: 'Lo siento, ha ocurrido un error. IntÃ©ntalo de nuevo.',
        timestamp: new Date(),
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  // ... JSX for the widget UI
}
\`\`\`

---

## 5. Rate Limiting Strategy

To prevent abuse while keeping the experience smooth:

### Per-Session Limits (Recommended for Free Tier)

\`\`\`typescript
// Limits per user session
const RATE_LIMITS = {
  messagesPerMinute: 5,
  messagesPerHour: 30,
  messagesPerDay: 100,
};
\`\`\`

### Implementation Options

1. **Session Storage** - Track in browser (client-side, easy to bypass)
2. **IP-based** - Use request IP + in-memory cache (recommended)
3. **Database** - Store in Supabase (most robust, adds latency)

Recommended: IP-based with in-memory Map, cleared every minute.

---

## 6. Cost Analysis

### Google Gemini Free Tier Usage

| Scenario | Daily Users | Messages/User | Total Messages | Within Free Tier? |
|----------|-------------|---------------|----------------|-------------------|
| Low | 10 | 10 | 100 | âœ… Yes (1,500 limit) |
| Medium | 30 | 20 | 600 | âœ… Yes |
| High | 50 | 30 | 1,500 | âœ… Just within limit |
| Very High | 100+ | 30+ | 3,000+ | âŒ Need paid tier |

### Paid Tier Estimate (if needed)

If exceeding free tier:
- **5,000 messages/month** Ã— 500 tokens avg = 2.5M tokens
- **Cost**: ~\$0.19/month (input) + \$0.75/month (output) = **~\$1/month**

---

## 7. Security Considerations

### Required Measures

1. **API Key Protection** - Never expose Gemini API key to client
2. **Rate Limiting** - Prevent abuse (see section 5)
3. **Input Sanitization** - Already handled by Zod schema
4. **Content Filtering** - Gemini has built-in safety filters
5. **No User Data Storage** - Keep chat history in session only (GDPR friendly)

### Optional Enhancements

1. **CAPTCHA** - Add for high-traffic scenarios
2. **User Auth** - Require Clerk login for chat access
3. **Logging** - Store anonymized metrics for monitoring

---

## 8. UI/UX Recommendations

### Design Principles

1. **Non-intrusive** - Small floating button, doesn't block content
2. **On-brand** - Betis green/gold colors
3. **Mobile-first** - Full-screen chat on mobile
4. **Quick responses** - Stream responses for perceived speed

### Suggested UI

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŸ¢ Asistente PeÃ±a BÃ©tica      [X]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  Â¡Hola! Soy el asistente de la      â”‚
â”‚  PeÃ±a BÃ©tica Escocesa. Â¿En quÃ©      â”‚
â”‚  puedo ayudarte?                     â”‚
â”‚                                      â”‚
â”‚  â€¢ InformaciÃ³n sobre el Betis        â”‚
â”‚  â€¢ PrÃ³ximos eventos                  â”‚
â”‚  â€¢ CÃ³mo unirte a la peÃ±a            â”‚
â”‚  â€¢ Trivia y porra                    â”‚
â”‚                                      â”‚
â”‚  [User message bubble]               â”‚
â”‚                                      â”‚
â”‚  [Assistant response bubble]         â”‚
â”‚                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” [Send]   â”‚
â”‚ â”‚ Escribe tu mensaje...  â”‚          â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

---

## 9. Feature Flag Integration

Add feature flag for gradual rollout:

\`\`\`typescript
// src/lib/featureFlags.ts
export type FeatureName = 
  | 'chat-assistant'  // New flag
  | 'show-trivia-game'
  // ... existing flags
\`\`\`

\`\`\`env
# .env.local - disabled by default
NEXT_PUBLIC_FEATURE_CHAT_ASSISTANT=false
\`\`\`

---

## 10. Testing Strategy

### Unit Tests

\`\`\`typescript
// tests/unit/chat/topicFilter.test.ts
describe('Topic Filter', () => {
  it('allows Betis-related questions', () => {
    expect(isLikelyOnTopic('Â¿QuiÃ©n es el entrenador del Betis?')).toBe(true);
  });

  it('allows Scottish football questions', () => {
    expect(isLikelyOnTopic('Tell me about Scottish football')).toBe(true);
  });

  it('allows peÃ±a-related questions', () => {
    expect(isLikelyOnTopic('Â¿DÃ³nde estÃ¡ el Polwarth Tavern?')).toBe(true);
  });

  it('flags potentially off-topic messages', () => {
    expect(isLikelyOnTopic('Write me a Python script to hack NASA')).toBe(false);
  });
});
\`\`\`

### E2E Tests

\`\`\`typescript
// e2e/chat.spec.ts
test('chat widget responds to Betis questions', async ({ page }) => {
  await page.goto('/');
  await page.click('[data-testid="chat-toggle"]');
  await page.fill('[data-testid="chat-input"]', 'Â¿CuÃ¡ndo juega el Betis?');
  await page.click('[data-testid="chat-send"]');
  await expect(page.locator('[data-testid="chat-response"]')).toBeVisible();
});
\`\`\`

---

## 11. Implementation Phases

### Phase 1: MVP (1-2 days)
- [ ] Set up Gemini API client
- [ ] Create \`/api/chat\` endpoint
- [ ] Basic ChatWidget component
- [ ] System prompt with topic restrictions
- [ ] Feature flag integration

### Phase 2: Polish (1 day)
- [ ] Streaming responses
- [ ] Rate limiting
- [ ] Improved UI/UX
- [ ] Mobile responsiveness

### Phase 3: Production (1 day)
- [ ] Error tracking (Sentry)
- [ ] Usage metrics
- [ ] A/B testing readiness
- [ ] Documentation

---

## 12. Alternative: Vercel AI SDK

For streaming responses and better DX, consider the Vercel AI SDK:

\`\`\`bash
npm install ai @ai-sdk/google
\`\`\`

\`\`\`typescript
// src/app/api/chat/route.ts
import { google } from '@ai-sdk/google';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: google('gemini-1.5-flash'),
    system: SYSTEM_PROMPT,
    messages,
  });

  return result.toDataStreamResponse();
}
\`\`\`

This provides built-in streaming, React hooks, and better error handling.

---

## 13. Decision

**Recommended approach:**
1. **Provider**: Google Gemini (free tier)
2. **SDK**: Vercel AI SDK for streaming support
3. **Topic restriction**: System prompt + keyword pre-filter
4. **UI**: Floating widget with Betis branding
5. **Rate limiting**: IP-based, 5 msg/min, 30 msg/hour

---

## References

- [Google Gemini API Documentation](https://ai.google.dev/docs)
- [Gemini Pricing](https://ai.google.dev/pricing)
- [Vercel AI SDK Documentation](https://sdk.vercel.ai/docs)
- [Next.js API Routes](https://nextjs.org/docs/app/building-your-application/routing/route-handlers)
- [Groq API](https://console.groq.com/docs/quickstart) (alternative)
